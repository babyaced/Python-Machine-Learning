{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "YelpDataAnalysis.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "k4RkclHxmH3b",
        "kBVZ-qphmteg"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/babyaced/Python-Machine-Learning/blob/master/YelpDataAnalysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CJ2j1OwjpP5i"
      },
      "source": [
        "# Choose one of steps with letter options"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ho-BiRaJnPXt"
      },
      "source": [
        "#First Install DeltaTFIDF Vectorizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6de8TbxwnWTV",
        "outputId": "e9d69f64-4069-470a-8220-d3eb65e7818f"
      },
      "source": [
        "#Install Delta TFIDF Vectorizer\n",
        "!pip install sklearn-deltatfidf\n",
        "!pip install libsvm"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting sklearn-deltatfidf\n",
            "  Downloading https://files.pythonhosted.org/packages/bf/26/1581ec9bac011a565b50cd86c7755be073c6a2caa3de07d41338ae71484c/sklearn_deltatfidf-0.3-py3-none-any.whl\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from sklearn-deltatfidf) (1.18.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sklearn-deltatfidf) (1.15.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from sklearn-deltatfidf) (0.22.2.post1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from sklearn-deltatfidf) (1.4.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->sklearn-deltatfidf) (0.17.0)\n",
            "Installing collected packages: sklearn-deltatfidf\n",
            "Successfully installed sklearn-deltatfidf-0.3\n",
            "Collecting libsvm\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4b/11/c7700d0cd3a21eef2d7d996256277fc640ccd4f84717c10228cb6c1567dc/libsvm-3.23.0.4.tar.gz (170kB)\n",
            "\u001b[K     |████████████████████████████████| 174kB 6.0MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: libsvm\n",
            "  Building wheel for libsvm (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for libsvm: filename=libsvm-3.23.0.4-cp36-cp36m-linux_x86_64.whl size=233336 sha256=c760d12618910b059835af93990aae20789f0460e24fb312fd3cfe8a63e26890\n",
            "  Stored in directory: /root/.cache/pip/wheels/5e/9e/b5/dbb033107407eec2f52b8cd24cf024a4b9ec8b62ea5aee995a\n",
            "Successfully built libsvm\n",
            "Installing collected packages: libsvm\n",
            "Successfully installed libsvm-3.23.0.4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u_DSS6XFlpb_"
      },
      "source": [
        "# 1) Import libraries and download Datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l6O1NgpNcCh6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d696588b-d5fe-4a72-f6bb-d95aa9b5d626"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import string # Imports the library\n",
        "\n",
        "\n",
        "\n",
        "import nltk  #imports the natural language toolkit\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "#Import Delta TFIDF Vectorizer\n",
        "from sklearn_deltatfidf import DeltaTfidfVectorizer \n",
        "\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from sklearn.pipeline import Pipeline\n",
        "from imblearn.pipeline import make_pipeline\n",
        "\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn import svm\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "\n",
        "nltk.download('wordnet')\n",
        "nltk.download('stopwords') # download stopwords dataset\n",
        "\n",
        "stopwords = stopwords.words('english')\n",
        "\n",
        "print(stopwords)\n",
        "\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).\n",
            "  \"(https://pypi.org/project/six/).\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.neighbors.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.neighbors. Anything that cannot be imported from sklearn.neighbors is now part of the private API.\n",
            "  warnings.warn(message, FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "04LRQFeLl1Wv"
      },
      "source": [
        "# 2a) Use Smaller Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        },
        "id": "LRJqhrU3PWbu",
        "outputId": "83472d66-1704-4135-8991-7e5f20b6adcb"
      },
      "source": [
        "# 980 review dataset\n",
        "data = pd.read_csv('YelpDataset1000.csv')\n",
        "\n",
        "#print('X Length: ',len(X), ' X Shape: ', X.shape)\n",
        "\n",
        "data.dropna()\n",
        "data['review']=data.review.str[2:-2]\n",
        "data['author']=data.author.str[2:-2]\n",
        "data['date']=data.date.str[2:-2]\n",
        "data['rating']=data.rating.str[2:-2]\n",
        "data['restaurant']=data.restaurant.str[2:-2]\n",
        "data['rating']=data.rating.str[:1]\n",
        "data['rating']= pd.to_numeric(data['rating'])\n",
        "\n",
        "print('1 Star Ratings ',len(data[data['rating']==1]))\n",
        "print('2 Star Ratings ',len(data[data['rating']==2]))\n",
        "print('3 Star Ratings ',len(data[data['rating']==3]))\n",
        "print('4 Star Ratings ',len(data[data['rating']==4]))\n",
        "print('5 Star Ratings ',len(data[data['rating']==5]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-f366503b3ea1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# 980 review dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'YelpDataset1000.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#print('X Length: ',len(X), ' X Shape: ', X.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    686\u001b[0m     )\n\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 688\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    689\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 454\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    946\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    947\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 948\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    950\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1178\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1180\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1181\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   2008\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2009\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2010\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2011\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2012\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'YelpDataset1000.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F-wxYtR-mA8C"
      },
      "source": [
        "# 2b) Use Bigger Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        },
        "id": "RqRTu6OF3w1Y",
        "outputId": "f097582a-10a7-4b99-b504-5779a5d41b40"
      },
      "source": [
        "# 10,000 review dataset\n",
        "data = pd.read_csv('YelpDataset10000(1).csv')\n",
        "\n",
        "data.dropna()\n",
        "\n",
        "print('1 Star Ratings ',len(data[data['stars']==1]))\n",
        "print('2 Star Ratings ',len(data[data['stars']==2]))\n",
        "print('3 Star Ratings ',len(data[data['stars']==3]))\n",
        "print('4 Star Ratings ',len(data[data['stars']==4]))\n",
        "print('5 Star Ratings ',len(data[data['stars']==5]))\n",
        "\n",
        "data.head()\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1 Star Ratings  749\n",
            "2 Star Ratings  927\n",
            "3 Star Ratings  1461\n",
            "4 Star Ratings  3526\n",
            "5 Star Ratings  3337\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>stars</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>U can go there n check the car out. If u wanna...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>Disgusting!  Had a Groupon so my daughter and ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>I've eaten here many times, but none as bad as...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>I have always been a fan of Burlington's deals...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>Another night meeting friends here.  I have to...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   stars                                               text\n",
              "0      1  U can go there n check the car out. If u wanna...\n",
              "1      1  Disgusting!  Had a Groupon so my daughter and ...\n",
              "2      1  I've eaten here many times, but none as bad as...\n",
              "3      1  I have always been a fan of Burlington's deals...\n",
              "4      1  Another night meeting friends here.  I have to..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Hfcij3kaz7F"
      },
      "source": [
        "# 2c) Use Balanced Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yrqycDvTa8JI",
        "outputId": "f2e7c8de-4812-4033-d361-8f98ec34522f"
      },
      "source": [
        "# 3745 review dataset\n",
        "data = pd.read_csv('YelpDataset3745.csv')\n",
        "\n",
        "data.dropna()\n",
        "\n",
        "print('1 Star Ratings ',len(data[data['stars']==1]))\n",
        "print('2 Star Ratings ',len(data[data['stars']==2]))\n",
        "print('3 Star Ratings ',len(data[data['stars']==3]))\n",
        "print('4 Star Ratings ',len(data[data['stars']==4]))\n",
        "print('5 Star Ratings ',len(data[data['stars']==5]))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1 Star Ratings  749\n",
            "2 Star Ratings  749\n",
            "3 Star Ratings  749\n",
            "4 Star Ratings  749\n",
            "5 Star Ratings  749\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k4RkclHxmH3b"
      },
      "source": [
        "# (Optional): Restrict Dataset to 1 and 5 star reviews"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lqm-cZ3IH1tX"
      },
      "source": [
        "data = data[(data['rating'] == 1) | (data['rating'] == 5)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oh41Zg8imQxK"
      },
      "source": [
        "# 3a) Clean and Lemmatize Reviews"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mVvNiTg3PqDO"
      },
      "source": [
        "#Could be detrimental to accuracy\n",
        "wn=nltk.WordNetLemmatizer()\n",
        "\n",
        "def clean_review(revw):\n",
        "   #remove weird char\n",
        "  revw = revw.replace('xa0',' ')\n",
        "\n",
        "  #remove punctuation\n",
        "  nopunc = [char for char in revw if char not in string.punctuation]\n",
        "  nopunc = ''.join(nopunc)\n",
        "\n",
        "  #remove stopwords\n",
        "  token_text = [word for word in nopunc.split() if word.lower() not in stopwords]\n",
        "\n",
        "  #perform lemmatization\n",
        "  cleantext = ' '.join(wn.lemmatize(word) for word in token_text)\n",
        "    \n",
        "  return cleantext\n",
        "\n",
        "data['cleantext'] = data['text'].apply(clean_review)\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zY717KLALLSj"
      },
      "source": [
        "# 3b) Only Clean Reviews"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bRNF6Fd_LJy4"
      },
      "source": [
        "def clean_review(revw):\n",
        "  #remove weird char\n",
        "  revw = revw.replace('xa0',' ')\n",
        "\n",
        "  #remove punctuation\n",
        "  nopunc = [char for char in revw if char not in string.punctuation]\n",
        "  nopunc = ''.join(nopunc)\n",
        "\n",
        "  #remove stopwords\n",
        "  token_text = [word for word in nopunc.split() if word.lower() not in stopwords]\n",
        "\n",
        "  #skip lemmatization\n",
        "  cleantext = ' '.join(word for word in token_text)\n",
        "    \n",
        "  return cleantext\n",
        "\n",
        "data['cleantext'] = data['text'].apply(clean_review)\n",
        "\n",
        "  \n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VefJNuI71BFk"
      },
      "source": [
        "# Cross Validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rb_RMfDF1Gj0"
      },
      "source": [
        "def cv(k, X,Y, pipeline, average_method):\n",
        "  kfold = StratifiedKFold(n_splits=k, shuffle=True, random_state=777)\n",
        "  accuracy = []\n",
        "  precision = []\n",
        "  recall = []\n",
        "  f1 = []\n",
        "  for train, test in kfold.split(X, Y):\n",
        "\n",
        "      fit = pipeline.fit(X[train], Y[train])\n",
        "      prediction = fit.predict(X[test])\n",
        "      scores = fit.score(X[test],Y[test])\n",
        "        \n",
        "      accuracy.append(scores * 100)\n",
        "      precision.append(precision_score(Y[test], prediction, average=average_method)*100)\n",
        "      print('              1            2             3            4            5')\n",
        "      print('precision:',precision_score(Y[test], prediction, average=None))\n",
        "      recall.append(recall_score(Y[test], prediction, average=average_method)*100)\n",
        "      print('recall:   ',recall_score(Y[test], prediction, average=None))\n",
        "      f1.append(f1_score(Y[test], prediction, average=average_method)*100)\n",
        "      print('f1 score: ',f1_score(Y[test], prediction, average=None))\n",
        "      print('-'*50)\n",
        "\n",
        "  print(\"accuracy: %.2f%% (+/- %.2f%%)\" % (np.mean(accuracy), np.std(accuracy)))\n",
        "  print(\"precision: %.2f%% (+/- %.2f%%)\" % (np.mean(precision), np.std(precision)))\n",
        "  print(\"recall: %.2f%% (+/- %.2f%%)\" % (np.mean(recall), np.std(recall)))\n",
        "  print(\"f1 score: %.2f%% (+/- %.2f%%)\" % (np.mean(f1), np.std(f1)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kBVZ-qphmteg"
      },
      "source": [
        "#4a) Use Count Vectorizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WTl1eWHZ5zAj",
        "outputId": "590a745a-bc9b-43fc-ece2-9f6ce8a03ee2"
      },
      "source": [
        "#Count Vectorizer\n",
        "ngram_vect = CountVectorizer(ngram_range=(1,1))\n",
        "cv = ngram_vect.fit_transform(data['cleanReview'])\n",
        "\n",
        "X = cv\n",
        "y = data['rating']\n",
        "\n",
        "#print(X)\n",
        "#print(y)\n",
        "\n",
        "print('X Shape: ', X.shape)\n",
        "print(' y Shape: ', y.shape)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size = 0.33, random_state=42)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X Shape:  (10000, 34038)\n",
            " y Shape:  (10000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YSBEHLhbm_3G"
      },
      "source": [
        "#4b) Use Delta TFIDF Vectorizer\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "KinpIY-GeNtI",
        "outputId": "29c6663c-0d5e-465d-a348-9e748937393e"
      },
      "source": [
        "dtfidf = DeltaTfidfVectorizer(ngram_range=(1,3))\n",
        "rating = data['stars'].tolist()\n",
        "review = data['cleantext'].tolist()\n",
        "review = [str(i) for i in review]\n",
        "dtv = dtfidf.fit_transform(review, rating)\n",
        "\n",
        "X = dtv\n",
        "y = data['stars']\n",
        "\n",
        "print('X Shape: ', X.shape)\n",
        "print('y Shape: ', y.shape)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(dtv, rating, test_size=0.33, random_state=42)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-5b5aabfb1231>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mreview\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'cleantext'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mreview\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreview\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mdtv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtfidf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreview\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: fit_transform() missing 1 required positional argument: 'y'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MMWP6VV59xih"
      },
      "source": [
        "# 4c) Use TFIDF Vectorizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y9qoyZoU92Lw",
        "outputId": "9dd77174-ce14-4e7b-a873-2fc2580b3578"
      },
      "source": [
        "tfidf = TfidfVectorizer(ngram_range=(1,3))\n",
        "rating = data['stars'].tolist()\n",
        "review = data['cleantext'].tolist()\n",
        "review = [str(i) for i in review]\n",
        "tv = tfidf.fit_transform(review)\n",
        "\n",
        "X = tv\n",
        "y = data['stars']\n",
        "\n",
        "print('X Shape: ', X.shape)\n",
        "print('y Shape: ', y.shape)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(tv, rating, test_size=0.33, random_state=42)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X Shape:  (10000, 1073289)\n",
            "y Shape:  (10000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V2uLk-L1bw9v"
      },
      "source": [
        "# (Optional) Oversample Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ndhAaMnbb388",
        "outputId": "5d7372fa-aab1-42f0-80d1-df3f5c07d8c0"
      },
      "source": [
        "\n",
        "\n",
        "\"\"\"tv = TfidfVectorizer(stop_words=None)\n",
        "review = pd.Series(data['cleantext'])\n",
        "rating = pd.Series(data['stars'])\n",
        "#print(rating.type)\n",
        "testing_tfidf = tv.fit_transform(review)\n",
        "smt = SMOTE(random_state=42, k_neighbors = 1)\n",
        "X_SMOTE, y_SMOTE = smt.fit_sample(testing_tfidf, rating)\n",
        "\n",
        "\n",
        "X = X_SMOTE\n",
        "y = y_SMOTE\n",
        "\n",
        "#print('X Shape: ', X.shape)\n",
        "#print('y Shape: ', y.shape)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
        "#print(y)\n",
        "pd.DataFrame(X_SMOTE.todense()[y_SMOTE==2], columns= tv.get_feature_names())\"\"\"\n",
        "\n",
        "tfidf = TfidfVectorizer(stop_words=None, max_features=100000, ngram_range=(1, 3))\n",
        "lsvc = LinearSVC(multi_class='ovr')\n",
        "lr = LogisticRegression(max_iter =1000)\n",
        "SMOTE_pipeline = make_pipeline(tfidf,SMOTE(random_state=777),lr)\n",
        "cv(10, data.cleantext, data.stars, SMOTE_pipeline, 'macro')\n"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0       U go n check car u wanna buy 1 Thats wrong mov...\n",
            "1       Disgusting Groupon daughter tried outdated gau...\n",
            "2       Ive eaten many time none bad last night Servic...\n",
            "3       always fan Burlingtons deal however shopping o...\n",
            "4       Another night meeting friend laugh Waited anot...\n",
            "                              ...                        \n",
            "9995    Yes rock hipster joint dig place little bit sc...\n",
            "9996    4 star note folk rated place low must isolated...\n",
            "9997    Im normally one jump reviewing chain restauran...\n",
            "9998    Lets seewhat like Surprise Stadium Well 950 ta...\n",
            "9999    45 location 45 star average think Arizona real...\n",
            "Name: cleantext, Length: 10000, dtype: object\n",
            "0       1\n",
            "1       1\n",
            "2       1\n",
            "3       1\n",
            "4       1\n",
            "       ..\n",
            "9995    5\n",
            "9996    5\n",
            "9997    5\n",
            "9998    5\n",
            "9999    5\n",
            "Name: stars, Length: 10000, dtype: int64\n",
            "              1            2             3            4            5\n",
            "precision: [0.59493671 0.40206186 0.41791045 0.55084746 0.63988095]\n",
            "recall:    [0.62666667 0.41935484 0.38356164 0.55240793 0.64564565]\n",
            "f1 score:  [0.61038961 0.41052632 0.4        0.55162659 0.64275037]\n",
            "--------------------------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0       U go n check car u wanna buy 1 Thats wrong mov...\n",
            "1       Disgusting Groupon daughter tried outdated gau...\n",
            "2       Ive eaten many time none bad last night Servic...\n",
            "3       always fan Burlingtons deal however shopping o...\n",
            "4       Another night meeting friend laugh Waited anot...\n",
            "                              ...                        \n",
            "9995    Yes rock hipster joint dig place little bit sc...\n",
            "9996    4 star note folk rated place low must isolated...\n",
            "9997    Im normally one jump reviewing chain restauran...\n",
            "9998    Lets seewhat like Surprise Stadium Well 950 ta...\n",
            "9999    45 location 45 star average think Arizona real...\n",
            "Name: cleantext, Length: 10000, dtype: object\n",
            "0       1\n",
            "1       1\n",
            "2       1\n",
            "3       1\n",
            "4       1\n",
            "       ..\n",
            "9995    5\n",
            "9996    5\n",
            "9997    5\n",
            "9998    5\n",
            "9999    5\n",
            "Name: stars, Length: 10000, dtype: int64\n",
            "              1            2             3            4            5\n",
            "precision: [0.55128205 0.42682927 0.45454545 0.55202312 0.59668508]\n",
            "recall:    [0.57333333 0.37634409 0.4109589  0.54107649 0.64864865]\n",
            "f1 score:  [0.5620915  0.4        0.43165468 0.54649499 0.62158273]\n",
            "--------------------------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0       U go n check car u wanna buy 1 Thats wrong mov...\n",
            "1       Disgusting Groupon daughter tried outdated gau...\n",
            "2       Ive eaten many time none bad last night Servic...\n",
            "3       always fan Burlingtons deal however shopping o...\n",
            "4       Another night meeting friend laugh Waited anot...\n",
            "                              ...                        \n",
            "9995    Yes rock hipster joint dig place little bit sc...\n",
            "9996    4 star note folk rated place low must isolated...\n",
            "9997    Im normally one jump reviewing chain restauran...\n",
            "9998    Lets seewhat like Surprise Stadium Well 950 ta...\n",
            "9999    45 location 45 star average think Arizona real...\n",
            "Name: cleantext, Length: 10000, dtype: object\n",
            "0       1\n",
            "1       1\n",
            "2       1\n",
            "3       1\n",
            "4       1\n",
            "       ..\n",
            "9995    5\n",
            "9996    5\n",
            "9997    5\n",
            "9998    5\n",
            "9999    5\n",
            "Name: stars, Length: 10000, dtype: int64\n",
            "              1            2             3            4            5\n",
            "precision: [0.51948052 0.44565217 0.41044776 0.54471545 0.61280488]\n",
            "recall:    [0.53333333 0.44086022 0.37671233 0.5694051  0.6036036 ]\n",
            "f1 score:  [0.52631579 0.44324324 0.39285714 0.5567867  0.60816944]\n",
            "--------------------------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0       U go n check car u wanna buy 1 Thats wrong mov...\n",
            "1       Disgusting Groupon daughter tried outdated gau...\n",
            "2       Ive eaten many time none bad last night Servic...\n",
            "3       always fan Burlingtons deal however shopping o...\n",
            "4       Another night meeting friend laugh Waited anot...\n",
            "                              ...                        \n",
            "9995    Yes rock hipster joint dig place little bit sc...\n",
            "9996    4 star note folk rated place low must isolated...\n",
            "9997    Im normally one jump reviewing chain restauran...\n",
            "9998    Lets seewhat like Surprise Stadium Well 950 ta...\n",
            "9999    45 location 45 star average think Arizona real...\n",
            "Name: cleantext, Length: 10000, dtype: object\n",
            "0       1\n",
            "1       1\n",
            "2       1\n",
            "3       1\n",
            "4       1\n",
            "       ..\n",
            "9995    5\n",
            "9996    5\n",
            "9997    5\n",
            "9998    5\n",
            "9999    5\n",
            "Name: stars, Length: 10000, dtype: int64\n",
            "              1            2             3            4            5\n",
            "precision: [0.47727273 0.35051546 0.39285714 0.52762431 0.63897764]\n",
            "recall:    [0.56       0.3655914  0.37671233 0.54261364 0.5988024 ]\n",
            "f1 score:  [0.51533742 0.35789474 0.38461538 0.53501401 0.61823802]\n",
            "--------------------------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0       U go n check car u wanna buy 1 Thats wrong mov...\n",
            "1       Disgusting Groupon daughter tried outdated gau...\n",
            "2       Ive eaten many time none bad last night Servic...\n",
            "3       always fan Burlingtons deal however shopping o...\n",
            "4       Another night meeting friend laugh Waited anot...\n",
            "                              ...                        \n",
            "9995    Yes rock hipster joint dig place little bit sc...\n",
            "9996    4 star note folk rated place low must isolated...\n",
            "9997    Im normally one jump reviewing chain restauran...\n",
            "9998    Lets seewhat like Surprise Stadium Well 950 ta...\n",
            "9999    45 location 45 star average think Arizona real...\n",
            "Name: cleantext, Length: 10000, dtype: object\n",
            "0       1\n",
            "1       1\n",
            "2       1\n",
            "3       1\n",
            "4       1\n",
            "       ..\n",
            "9995    5\n",
            "9996    5\n",
            "9997    5\n",
            "9998    5\n",
            "9999    5\n",
            "Name: stars, Length: 10000, dtype: int64\n",
            "              1            2             3            4            5\n",
            "precision: [0.48837209 0.35106383 0.43650794 0.54624277 0.65229885]\n",
            "recall:    [0.56       0.35483871 0.37671233 0.53693182 0.67964072]\n",
            "f1 score:  [0.52173913 0.35294118 0.40441176 0.54154728 0.66568915]\n",
            "--------------------------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0       U go n check car u wanna buy 1 Thats wrong mov...\n",
            "1       Disgusting Groupon daughter tried outdated gau...\n",
            "2       Ive eaten many time none bad last night Servic...\n",
            "3       always fan Burlingtons deal however shopping o...\n",
            "4       Another night meeting friend laugh Waited anot...\n",
            "                              ...                        \n",
            "9995    Yes rock hipster joint dig place little bit sc...\n",
            "9996    4 star note folk rated place low must isolated...\n",
            "9997    Im normally one jump reviewing chain restauran...\n",
            "9998    Lets seewhat like Surprise Stadium Well 950 ta...\n",
            "9999    45 location 45 star average think Arizona real...\n",
            "Name: cleantext, Length: 10000, dtype: object\n",
            "0       1\n",
            "1       1\n",
            "2       1\n",
            "3       1\n",
            "4       1\n",
            "       ..\n",
            "9995    5\n",
            "9996    5\n",
            "9997    5\n",
            "9998    5\n",
            "9999    5\n",
            "Name: stars, Length: 10000, dtype: int64\n",
            "              1            2             3            4            5\n",
            "precision: [0.49438202 0.41463415 0.41428571 0.52513966 0.63444109]\n",
            "recall:    [0.58666667 0.3655914  0.39726027 0.53409091 0.62874251]\n",
            "f1 score:  [0.53658537 0.38857143 0.40559441 0.52957746 0.63157895]\n",
            "--------------------------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0       U go n check car u wanna buy 1 Thats wrong mov...\n",
            "1       Disgusting Groupon daughter tried outdated gau...\n",
            "2       Ive eaten many time none bad last night Servic...\n",
            "3       always fan Burlingtons deal however shopping o...\n",
            "4       Another night meeting friend laugh Waited anot...\n",
            "                              ...                        \n",
            "9995    Yes rock hipster joint dig place little bit sc...\n",
            "9996    4 star note folk rated place low must isolated...\n",
            "9997    Im normally one jump reviewing chain restauran...\n",
            "9998    Lets seewhat like Surprise Stadium Well 950 ta...\n",
            "9999    45 location 45 star average think Arizona real...\n",
            "Name: cleantext, Length: 10000, dtype: object\n",
            "0       1\n",
            "1       1\n",
            "2       1\n",
            "3       1\n",
            "4       1\n",
            "       ..\n",
            "9995    5\n",
            "9996    5\n",
            "9997    5\n",
            "9998    5\n",
            "9999    5\n",
            "Name: stars, Length: 10000, dtype: int64\n",
            "              1            2             3            4            5\n",
            "precision: [0.48863636 0.37373737 0.40650407 0.52147239 0.59065934]\n",
            "recall:    [0.57333333 0.40217391 0.34013605 0.48295455 0.64371257]\n",
            "f1 score:  [0.52760736 0.38743455 0.37037037 0.50147493 0.61604585]\n",
            "--------------------------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0       U go n check car u wanna buy 1 Thats wrong mov...\n",
            "1       Disgusting Groupon daughter tried outdated gau...\n",
            "2       Ive eaten many time none bad last night Servic...\n",
            "3       always fan Burlingtons deal however shopping o...\n",
            "4       Another night meeting friend laugh Waited anot...\n",
            "                              ...                        \n",
            "9995    Yes rock hipster joint dig place little bit sc...\n",
            "9996    4 star note folk rated place low must isolated...\n",
            "9997    Im normally one jump reviewing chain restauran...\n",
            "9998    Lets seewhat like Surprise Stadium Well 950 ta...\n",
            "9999    45 location 45 star average think Arizona real...\n",
            "Name: cleantext, Length: 10000, dtype: object\n",
            "0       1\n",
            "1       1\n",
            "2       1\n",
            "3       1\n",
            "4       1\n",
            "       ..\n",
            "9995    5\n",
            "9996    5\n",
            "9997    5\n",
            "9998    5\n",
            "9999    5\n",
            "Name: stars, Length: 10000, dtype: int64\n",
            "              1            2             3            4            5\n",
            "precision: [0.5        0.41791045 0.39333333 0.56695157 0.6497006 ]\n",
            "recall:    [0.65333333 0.30434783 0.40410959 0.56373938 0.6497006 ]\n",
            "f1 score:  [0.56647399 0.35220126 0.39864865 0.56534091 0.6497006 ]\n",
            "--------------------------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0       U go n check car u wanna buy 1 Thats wrong mov...\n",
            "1       Disgusting Groupon daughter tried outdated gau...\n",
            "2       Ive eaten many time none bad last night Servic...\n",
            "3       always fan Burlingtons deal however shopping o...\n",
            "4       Another night meeting friend laugh Waited anot...\n",
            "                              ...                        \n",
            "9995    Yes rock hipster joint dig place little bit sc...\n",
            "9996    4 star note folk rated place low must isolated...\n",
            "9997    Im normally one jump reviewing chain restauran...\n",
            "9998    Lets seewhat like Surprise Stadium Well 950 ta...\n",
            "9999    45 location 45 star average think Arizona real...\n",
            "Name: cleantext, Length: 10000, dtype: object\n",
            "0       1\n",
            "1       1\n",
            "2       1\n",
            "3       1\n",
            "4       1\n",
            "       ..\n",
            "9995    5\n",
            "9996    5\n",
            "9997    5\n",
            "9998    5\n",
            "9999    5\n",
            "Name: stars, Length: 10000, dtype: int64\n",
            "              1            2             3            4            5\n",
            "precision: [0.57142857 0.44761905 0.44067797 0.56214689 0.64450867]\n",
            "recall:    [0.58666667 0.51086957 0.35616438 0.56373938 0.66766467]\n",
            "f1 score:  [0.57894737 0.47715736 0.39393939 0.56294201 0.65588235]\n",
            "--------------------------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0       U go n check car u wanna buy 1 Thats wrong mov...\n",
            "1       Disgusting Groupon daughter tried outdated gau...\n",
            "2       Ive eaten many time none bad last night Servic...\n",
            "3       always fan Burlingtons deal however shopping o...\n",
            "4       Another night meeting friend laugh Waited anot...\n",
            "                              ...                        \n",
            "9995    Yes rock hipster joint dig place little bit sc...\n",
            "9996    4 star note folk rated place low must isolated...\n",
            "9997    Im normally one jump reviewing chain restauran...\n",
            "9998    Lets seewhat like Surprise Stadium Well 950 ta...\n",
            "9999    45 location 45 star average think Arizona real...\n",
            "Name: cleantext, Length: 10000, dtype: object\n",
            "0       1\n",
            "1       1\n",
            "2       1\n",
            "3       1\n",
            "4       1\n",
            "       ..\n",
            "9995    5\n",
            "9996    5\n",
            "9997    5\n",
            "9998    5\n",
            "9999    5\n",
            "Name: stars, Length: 10000, dtype: int64\n",
            "              1            2             3            4            5\n",
            "precision: [0.51136364 0.41573034 0.41984733 0.57848837 0.64655172]\n",
            "recall:    [0.60810811 0.39784946 0.37671233 0.56373938 0.67365269]\n",
            "f1 score:  [0.55555556 0.40659341 0.39711191 0.57101865 0.65982405]\n",
            "--------------------------------------------------\n",
            "accuracy: 54.30% (+/- 1.52%)\n",
            "precision: 50.42% (+/- 1.74%)\n",
            "recall: 50.98% (+/- 1.50%)\n",
            "f1 score: 50.58% (+/- 1.61%)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UrwG-jgUnsOY"
      },
      "source": [
        "#5a) Use Linear SVC Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3tOlhyEUs8NE",
        "outputId": "fb3db109-8c61-4f22-c297-01ec4e1bef37"
      },
      "source": [
        "#Linear SVC\n",
        "svc = LinearSVC(multi_class='ovr')\n",
        "svc.fit(X_train, y_train)\n",
        "\n",
        "LSVCpredictions = svc.predict(X_test)\n",
        "\n",
        "print(confusion_matrix(y_test, LSVCpredictions))\n",
        "print('\\n')\n",
        "print(classification_report(y_test,LSVCpredictions))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 87  20  17  72  78]\n",
            " [ 24  29  39 148  73]\n",
            " [  4  11  47 330  86]\n",
            " [  0   1  16 734 399]\n",
            " [  2   0   2 343 738]]\n",
            "\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.74      0.32      0.45       274\n",
            "           2       0.48      0.09      0.16       313\n",
            "           3       0.39      0.10      0.16       478\n",
            "           4       0.45      0.64      0.53      1150\n",
            "           5       0.54      0.68      0.60      1085\n",
            "\n",
            "    accuracy                           0.50      3300\n",
            "   macro avg       0.52      0.37      0.38      3300\n",
            "weighted avg       0.50      0.50      0.46      3300\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qtsHVqyRnyTC"
      },
      "source": [
        "#5b) Use Multinomial Naive Bayes Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "smewNPf-xatH",
        "outputId": "4e322d33-3851-45d8-f1e4-9b758630f21e"
      },
      "source": [
        "#Multinomial Naive Bayes\n",
        "nb = MultinomialNB()\n",
        "nb.fit(X_train, y_train)\n",
        "\n",
        "NBpredictions = nb.predict(X_test)\n",
        "\n",
        "print(confusion_matrix(y_test, NBpredictions))\n",
        "print('\\n')\n",
        "print(classification_report(y_test,NBpredictions))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1053   92    1    9    1]\n",
            " [  51 1066    0   17    4]\n",
            " [  92  487  167  384   22]\n",
            " [  45  200    9  775  125]\n",
            " [  83  123    3  549  460]]\n",
            "\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.80      0.91      0.85      1156\n",
            "           2       0.54      0.94      0.69      1138\n",
            "           3       0.93      0.14      0.25      1152\n",
            "           4       0.45      0.67      0.54      1154\n",
            "           5       0.75      0.38      0.50      1218\n",
            "\n",
            "    accuracy                           0.61      5818\n",
            "   macro avg       0.69      0.61      0.57      5818\n",
            "weighted avg       0.69      0.61      0.56      5818\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FB78MVEgRPBM"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f0nv7y2OoxEm"
      },
      "source": [
        "# 5c) Use SVC Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "za1RkZCxxXS1",
        "outputId": "f2adaf62-16f1-4ed5-a80d-03d25c1832eb"
      },
      "source": [
        "#SVC\n",
        "clf = svm.SVC()\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "CLFpredictions = clf.predict(X_test)\n",
        "\n",
        "print(confusion_matrix(y_test, CLFpredictions))\n",
        "print('\\n')\n",
        "print(classification_report(y_test,CLFpredictions))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1085    7    2   51   11]\n",
            " [  12 1007    4   97   18]\n",
            " [  11   22  749  323   47]\n",
            " [   2    2    7  837  306]\n",
            " [   2    1    2  435  778]]\n",
            "\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.98      0.94      0.96      1156\n",
            "           2       0.97      0.88      0.93      1138\n",
            "           3       0.98      0.65      0.78      1152\n",
            "           4       0.48      0.73      0.58      1154\n",
            "           5       0.67      0.64      0.65      1218\n",
            "\n",
            "    accuracy                           0.77      5818\n",
            "   macro avg       0.82      0.77      0.78      5818\n",
            "weighted avg       0.81      0.77      0.78      5818\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WpEDqG8DOysc"
      },
      "source": [
        "# 5d) Use RFC Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H9vbUndFPB7i",
        "outputId": "3192ea54-f67a-41c7-d05a-3b8ed17ca6ba"
      },
      "source": [
        "#RFC\n",
        "rfc = RandomForestClassifier()\n",
        "rfc.fit(X_train, y_train)\n",
        "\n",
        "RFCpredictions = rfc.predict(X_test)\n",
        "\n",
        "print(confusion_matrix(y_test, RFCpredictions))\n",
        "print('\\n')\n",
        "print(classification_report(y_test,RFCpredictions))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1082    2   35   22   15]\n",
            " [   5 1012   54   43   24]\n",
            " [  15    8  975  100   54]\n",
            " [   9   37  162  534  412]\n",
            " [  12   19   98  311  778]]\n",
            "\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.96      0.94      0.95      1156\n",
            "           2       0.94      0.89      0.91      1138\n",
            "           3       0.74      0.85      0.79      1152\n",
            "           4       0.53      0.46      0.49      1154\n",
            "           5       0.61      0.64      0.62      1218\n",
            "\n",
            "    accuracy                           0.75      5818\n",
            "   macro avg       0.75      0.75      0.75      5818\n",
            "weighted avg       0.75      0.75      0.75      5818\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tDOx08oxocf4"
      },
      "source": [
        "# 5e) Use KNN Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l3mZ82g2okPi",
        "outputId": "04f2bc8e-ff14-469a-9277-c681c375e2c5"
      },
      "source": [
        "#KNN\n",
        "knn = KNeighborsClassifier()\n",
        "knn.fit(X_train, y_train)\n",
        "KNNpredictions = knn.predict(X_test)\n",
        "\n",
        "print(confusion_matrix(y_test, KNNpredictions))\n",
        "print('\\n')\n",
        "print(classification_report(y_test,KNNpredictions))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 894    0  262    0    0]\n",
            " [   0  824  314    0    0]\n",
            " [   2    0 1150    0    0]\n",
            " [   2    3 1144    0    5]\n",
            " [   5    5 1196    1   11]]\n",
            "\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.99      0.77      0.87      1156\n",
            "           2       0.99      0.72      0.84      1138\n",
            "           3       0.28      1.00      0.44      1152\n",
            "           4       0.00      0.00      0.00      1154\n",
            "           5       0.69      0.01      0.02      1218\n",
            "\n",
            "    accuracy                           0.49      5818\n",
            "   macro avg       0.59      0.50      0.43      5818\n",
            "weighted avg       0.59      0.49      0.43      5818\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HxZWDtFdYT5q"
      },
      "source": [
        "# 5f) Use Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "raJcJ9AnYZ81",
        "outputId": "5a98e946-092e-41d3-90e7-213dd4529416"
      },
      "source": [
        "lr = LogisticRegression()\n",
        "lr.fit(X_train, y_train)\n",
        "LRpredictions = lr.predict(X_test)\n",
        "\n",
        "print(confusion_matrix(y_test, LRpredictions))\n",
        "print('\\n')\n",
        "print(classification_report(y_test,LRpredictions))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1071   40   32    4    9]\n",
            " [  46  990   68   24   10]\n",
            " [  35   86  855  133   43]\n",
            " [  23   57  185  580  309]\n",
            " [  29   24  133  296  736]]\n",
            "\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.89      0.93      0.91      1156\n",
            "           2       0.83      0.87      0.85      1138\n",
            "           3       0.67      0.74      0.71      1152\n",
            "           4       0.56      0.50      0.53      1154\n",
            "           5       0.66      0.60      0.63      1218\n",
            "\n",
            "    accuracy                           0.73      5818\n",
            "   macro avg       0.72      0.73      0.72      5818\n",
            "weighted avg       0.72      0.73      0.72      5818\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}